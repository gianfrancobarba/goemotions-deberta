version: "3.8"

services:
  model:
    build:
      context: .
      dockerfile: docker/Dockerfile.model
    runtime: nvidia
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility
      - PYTHONPATH=/app
      - MLFLOW_TRACKING_URI=/app/mlruns
    volumes:
      - ./app:/app                           # tutto il codice sorgente
      - ./data:/app/data                    # dataset raw + processed
      - ./model/models:/app/model/models    # modelli salvati, tokenizer
      - ./mlruns:/app/mlruns
    working_dir: /app
    container_name: goemotions-model
    command: ["sleep", "infinity"]

  api:
    build:
      context: .
      dockerfile: docker/Dockerfile.api
    environment:
      - PYTHONPATH=/app
    ports:
      - "8000:8000"
    depends_on:
      - model
    volumes:
      - ./app/api:/app/api
      - ./app/config:/app/config
      - ./app/utils:/app/utils
      - ./app/model:/app/model
      - ./model/models:/app/model/models

    working_dir: /app
    container_name: goemotions-api
    command: uvicorn api.main:app --host 0.0.0.0 --port 8000

  client:
    build:
      context: .
      dockerfile: docker/Dockerfile.client
    container_name: goemotions-client
    ports:
      - "3000:80"
    depends_on:
      - api
    volumes:
      - ./client:/app/client
    working_dir: /app/client

  mlflow:
    image: ghcr.io/mlflow/mlflow:latest
    ports:
      - "5000:5000"
    volumes:
      - ./mlruns:/app/mlruns
    environment:
      - MLFLOW_BACKEND_STORE_URI=/mlruns
    working_dir: /app
    command: mlflow ui --host 0.0.0.0 --port 5000 --backend-store-uri /app/mlruns

